{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Reinforcement Learning in Action - Chapter 5 - extended and refactored to compare the actor-critic to the n-step actor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "import numpy as np\n",
    "def square(x):\n",
    "    return np.square(x)\n",
    "x = np.arange(64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': # added this line for process safety\n",
    "    pool = mp.Pool(8)\n",
    "    squared = pool.map(square, [x[8*i:8*i+8] for i in range(8)])\n",
    "    squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In process 0\n",
      "In process 1\n",
      "In process 2\n",
      "In process 3\n",
      "In process 4\n",
      "In process 5\n",
      "In process 6\n",
      "In process 7\n"
     ]
    }
   ],
   "source": [
    "def square(i, x, queue):\n",
    "    print(\"In process {}\".format(i,))\n",
    "\n",
    "queue = mp.Queue()\n",
    "queue.put(np.square(x))\n",
    "processes = []\n",
    "if __name__ == '__main__': #adding this for process safety\n",
    "    x = np.arange(64)\n",
    "    for i in range(8):\n",
    "        start_index = 8*i\n",
    "        proc = mp.Process(target=square,args=(i,x[start_index:start_index+8],\n",
    "                         queue)) \n",
    "        proc.start()\n",
    "        processes.append(proc)\n",
    "\n",
    "    for proc in processes:\n",
    "        proc.join()\n",
    "\n",
    "    for proc in processes:\n",
    "        proc.terminate()\n",
    "\n",
    "    results = []\n",
    "    while not queue.empty():\n",
    "        results.append(queue.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([   0,    1,    4,    9,   16,   25,   36,   49,   64,   81,  100,\n",
       "         121,  144,  169,  196,  225,  256,  289,  324,  361,  400,  441,\n",
       "         484,  529,  576,  625,  676,  729,  784,  841,  900,  961, 1024,\n",
       "        1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849,\n",
       "        1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916,\n",
       "        3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartpole-v1 with actor-critic and N-step actor-critic trained distrubuted over CPU threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "import gym\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "CPU_COUNT = mp.cpu_count()\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.l1 = nn.Linear(4,25)\n",
    "        self.l2 = nn.Linear(25,50)\n",
    "        self.actor_lin1 = nn.Linear(50,2)\n",
    "        self.l3 = nn.Linear(50,25)\n",
    "        self.critic_lin1 = nn.Linear(25,1)\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x,dim=0)\n",
    "        y = F.relu(self.l1(x))\n",
    "        y = F.relu(self.l2(y))\n",
    "        actor = F.log_softmax(self.actor_lin1(y),dim=0)\n",
    "        c = F.relu(self.l3(y.detach()))\n",
    "        critic = torch.tanh(self.critic_lin1(c))\n",
    "        return actor, critic\n",
    "\n",
    "\n",
    "def worker(t, worker_model, counter, params, N_steps):\n",
    "    worker_env = gym.make(\"CartPole-v1\")\n",
    "    worker_env._max_episode_steps = 1000\n",
    "    worker_env.reset()\n",
    "    worker_opt = optim.Adam(lr=1e-4,params=worker_model.parameters())\n",
    "    worker_opt.zero_grad()\n",
    "    for i in range(params['epochs']):\n",
    "        worker_opt.zero_grad()\n",
    "        if N_steps > 1:\n",
    "            values, logprobs, rewards, G = run_episode(worker_env,worker_model, N_steps)\n",
    "            actor_loss,critic_loss,eplen = update_params(worker_opt,values,logprobs,rewards, G)\n",
    "        else:\n",
    "            values, logprobs, rewards = run_episode(worker_env,worker_model, N_steps)\n",
    "            actor_loss,critic_loss,eplen = update_params(worker_opt,values,logprobs,rewards)            \n",
    "        counter.value = counter.value + 1\n",
    "\n",
    "        \n",
    "def run_episode(worker_env, worker_model, N_steps=10):\n",
    "    \n",
    "    if N_steps > 1:\n",
    "        raw_state = np.array(worker_env.env.state)\n",
    "        state = torch.from_numpy(raw_state).float()\n",
    "        values, logprobs, rewards = [],[],[]\n",
    "        done = False\n",
    "        j=0\n",
    "        G=torch.Tensor([0])\n",
    "        while (j < N_steps and done == False):\n",
    "            j+=1\n",
    "            policy, value = worker_model(state)\n",
    "            values.append(value)\n",
    "            logits = policy.view(-1)\n",
    "            action_dist = torch.distributions.Categorical(logits=logits)\n",
    "            action = action_dist.sample()\n",
    "            logprob_ = policy.view(-1)[action]\n",
    "            logprobs.append(logprob_)\n",
    "            state_, _, done, info = worker_env.step(action.detach().numpy())\n",
    "            state = torch.from_numpy(state_).float()\n",
    "            if done:\n",
    "                reward = -10\n",
    "                worker_env.reset()\n",
    "            else:\n",
    "                reward = 1.0\n",
    "                G = value.detach()\n",
    "            rewards.append(reward)\n",
    "        return values, logprobs, rewards, G\n",
    "\n",
    "    else:\n",
    "        state = torch.from_numpy(worker_env.env.state).float()\n",
    "        values, logprobs, rewards = [],[],[]\n",
    "        done = False\n",
    "        j=0\n",
    "        while (done == False):\n",
    "            j+=1\n",
    "            policy, value = worker_model(state)\n",
    "            values.append(value)\n",
    "            logits = policy.view(-1)\n",
    "            action_dist = torch.distributions.Categorical(logits=logits)\n",
    "            action = action_dist.sample()\n",
    "            logprob_ = policy.view(-1)[action]\n",
    "            logprobs.append(logprob_)\n",
    "            state_, _, done, info = worker_env.step(action.detach().numpy())\n",
    "            state = torch.from_numpy(state_).float()\n",
    "            if done:\n",
    "                reward = -10\n",
    "                worker_env.reset()\n",
    "            else:\n",
    "                reward = 1.0\n",
    "            rewards.append(reward)        \n",
    "        return values, logprobs, rewards\n",
    "\n",
    "    \n",
    "def update_params(worker_opt,values,logprobs,rewards,G=None,clc=0.1,gamma=0.95):\n",
    "    rewards = torch.Tensor(rewards).flip(dims=(0,)).view(-1)\n",
    "    logprobs = torch.stack(logprobs).flip(dims=(0,)).view(-1)\n",
    "    values = torch.stack(values).flip(dims=(0,)).view(-1)\n",
    "    Returns = []\n",
    "    \n",
    "    # this is where G is ultimately used\n",
    "    ret_ = G if G is not None else torch.Tensor([0])\n",
    "    \n",
    "    for r in range(rewards.shape[0]):\n",
    "        ret_ = rewards[r] + gamma * ret_\n",
    "        Returns.append(ret_)\n",
    "    Returns = torch.stack(Returns).view(-1)\n",
    "    Returns = F.normalize(Returns,dim=0)\n",
    "    actor_loss = -1*logprobs * (Returns - values.detach())\n",
    "    critic_loss = torch.pow(values - Returns,2)\n",
    "    loss = actor_loss.sum() + clc*critic_loss.sum()\n",
    "    loss.backward()\n",
    "    worker_opt.step()\n",
    "    return actor_loss, critic_loss, len(rewards)\n",
    "\n",
    "\n",
    "def train_and_test(N_steps):\n",
    "    \"\"\"\n",
    "    This will not record losses for plotting. \n",
    "    If you want to record losses, you'll need to create a multiprocessing shared array and\n",
    "        modify the worker function to write each loss to it.\n",
    "        See < https://docs.python.org/3/library/multiprocessing.html > \n",
    "    Alternatively, you could use process locks to safely write to a file.\n",
    "    \"\"\"\n",
    "    \n",
    "    MasterNode = ActorCritic()\n",
    "    MasterNode.share_memory()\n",
    "    processes = []\n",
    "    params = {\n",
    "        'epochs':1000,\n",
    "        'n_workers':(CPU_COUNT-1),\n",
    "    }\n",
    "    counter = mp.Value('i',0)\n",
    "    if __name__ == '__main__': #adding this for process safety\n",
    "        for i in trange(params['n_workers']):\n",
    "            p = mp.Process(target=worker, args=(i,MasterNode,counter,params,N_steps))\n",
    "            p.start() \n",
    "            processes.append(p)\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        for p in processes:\n",
    "            p.terminate()\n",
    "\n",
    "    print(counter.value,processes[1].exitcode)\n",
    "    \n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    env._max_episode_steps = 1000\n",
    "    env.reset()\n",
    "\n",
    "    last_loss = 0\n",
    "    durations = []\n",
    "    for i in trange(5000):\n",
    "        state_ = np.array(env.env.state)\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        logits,value = MasterNode(state)\n",
    "        action_dist = torch.distributions.Categorical(logits=logits)\n",
    "        action = action_dist.sample()\n",
    "        state2, reward, done, info = env.step(action.detach().numpy())\n",
    "        if done:\n",
    "            duration = i - last_loss\n",
    "            durations.append(duration)\n",
    "            print(f\"Lost after {duration} steps.\")\n",
    "            env.reset()\n",
    "            last_loss = i\n",
    "        state_ = np.array(env.env.state)\n",
    "        state = torch.from_numpy(state_).float()\n",
    "        env.render()\n",
    "\n",
    "    env.close()\n",
    "    print(f\"durations: mean: {np.mean(durations)}, std: {np.std(durations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d5bad79cae4175a2fa064d4f2477c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10992 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44917d7acb24b7f8f9cd6080328c108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 121 steps.\n",
      "Lost after 335 steps.\n",
      "Lost after 358 steps.\n",
      "Lost after 177 steps.\n",
      "Lost after 230 steps.\n",
      "Lost after 209 steps.\n",
      "Lost after 173 steps.\n",
      "Lost after 372 steps.\n",
      "Lost after 322 steps.\n",
      "Lost after 162 steps.\n",
      "Lost after 98 steps.\n",
      "Lost after 246 steps.\n",
      "Lost after 118 steps.\n",
      "Lost after 212 steps.\n",
      "Lost after 209 steps.\n",
      "Lost after 421 steps.\n",
      "Lost after 152 steps.\n",
      "Lost after 218 steps.\n",
      "Lost after 155 steps.\n",
      "Lost after 182 steps.\n",
      "Lost after 355 steps.\n",
      "durations: mean: 229.76190476190476, std: 91.62340351985598\n"
     ]
    }
   ],
   "source": [
    "train_and_test(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6552b7596524242b696e4f2a2320a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10732 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e4e5826e63d4a7886aeb83ec55f9f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 292 steps.\n",
      "Lost after 147 steps.\n",
      "Lost after 472 steps.\n",
      "Lost after 285 steps.\n",
      "Lost after 171 steps.\n",
      "Lost after 550 steps.\n",
      "Lost after 248 steps.\n",
      "Lost after 197 steps.\n",
      "Lost after 203 steps.\n",
      "Lost after 158 steps.\n",
      "Lost after 189 steps.\n",
      "Lost after 301 steps.\n",
      "Lost after 886 steps.\n",
      "Lost after 379 steps.\n",
      "Lost after 169 steps.\n",
      "Lost after 140 steps.\n",
      "Lost after 138 steps.\n",
      "durations: mean: 289.70588235294116, std: 188.56603296704137\n"
     ]
    }
   ],
   "source": [
    "train_and_test(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adbd42af2cfb4650a6ab8c00c18efbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10915 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774e010cf1b64b439d4a634f20f16973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 205 steps.\n",
      "Lost after 497 steps.\n",
      "Lost after 556 steps.\n",
      "Lost after 520 steps.\n",
      "Lost after 250 steps.\n",
      "Lost after 529 steps.\n",
      "Lost after 262 steps.\n",
      "Lost after 648 steps.\n",
      "Lost after 206 steps.\n",
      "Lost after 653 steps.\n",
      "Lost after 524 steps.\n",
      "durations: mean: 440.90909090909093, std: 166.3705910121107\n"
     ]
    }
   ],
   "source": [
    "train_and_test(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180612e761264d0c925d94680e72e282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10915 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9146b23224ce4013a2d5a51132c490e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 168 steps.\n",
      "Lost after 357 steps.\n",
      "Lost after 237 steps.\n",
      "Lost after 394 steps.\n",
      "Lost after 223 steps.\n",
      "Lost after 357 steps.\n",
      "Lost after 158 steps.\n",
      "Lost after 421 steps.\n",
      "Lost after 286 steps.\n",
      "Lost after 772 steps.\n",
      "Lost after 588 steps.\n",
      "Lost after 402 steps.\n",
      "Lost after 258 steps.\n",
      "Lost after 292 steps.\n",
      "durations: mean: 350.92857142857144, std: 160.20186564176473\n"
     ]
    }
   ],
   "source": [
    "train_and_test(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fdc8b814c54f45979592617e743bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10949 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e465d6228ce14a05b79d7ba8fb491023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 204 steps.\n",
      "Lost after 865 steps.\n",
      "Lost after 278 steps.\n",
      "Lost after 332 steps.\n",
      "Lost after 339 steps.\n",
      "Lost after 272 steps.\n",
      "Lost after 1000 steps.\n",
      "Lost after 343 steps.\n",
      "Lost after 281 steps.\n",
      "Lost after 555 steps.\n",
      "durations: mean: 446.9, std: 259.55594772611164\n"
     ]
    }
   ],
   "source": [
    "train_and_test(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facfc27c927f4e9a80d11018bcc77a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10960 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375aff4a1799463893fdfcdbdfc9bd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lost after 501 steps.\n",
      "Lost after 546 steps.\n",
      "Lost after 289 steps.\n",
      "Lost after 360 steps.\n",
      "Lost after 409 steps.\n",
      "Lost after 327 steps.\n",
      "Lost after 363 steps.\n",
      "Lost after 453 steps.\n",
      "Lost after 362 steps.\n",
      "Lost after 283 steps.\n",
      "Lost after 422 steps.\n",
      "Lost after 305 steps.\n",
      "Lost after 341 steps.\n",
      "durations: mean: 381.61538461538464, std: 77.83368705282237\n"
     ]
    }
   ],
   "source": [
    "train_and_test(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-rl-notebooks-poetry",
   "language": "python",
   "name": "deep-rl-notebooks-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
