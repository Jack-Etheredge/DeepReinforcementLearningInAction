{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaper 8 - Intrinsic Curiosity Module\n",
    "#### Deep Reinforcement Learning *in Action*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from nes_py.wrappers import JoypadSpace #A\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT #B\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, COMPLEX_MOVEMENT) #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "for step in range(2500): #D\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize #A\n",
    "import numpy as np\n",
    "\n",
    "def downscale_obs(obs, new_size=(42,42), to_gray=True):\n",
    "    if to_gray:\n",
    "        return resize(obs, new_size, anti_aliasing=True).max(axis=2) #B\n",
    "    else:\n",
    "        return resize(obs, new_size, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e3b044cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXuMnXl537/Pec9tzpmbZzy2x5dds8t62eW2EFgS0aYbLtWGVgUqIYU0EZW2BSlBIm2qsrRSSypF2koQqNQKCRSUTUpDkUIKohCyWkgoDSwssCzeq9derz0ez3hmPJcz53759Y85pj7z/b7r47kce3ifj2SN55n3fX+X9/297znf97lYCAGO4ySP1I3ugOM4NwZf/I6TUHzxO05C8cXvOAnFF7/jJBRf/I6TUHzxO05C8cXvOAllW4vfzO43s+fM7AUze3CnOuU4zu5jW/XwM7MIwPMA3glgBsAPAbw/hPB03D7Ffdmw7/BQjy1l3H7a2lvq08/71ud27aC3NGEOYttB+UaqXm63bTXvBWv01U5H9KjUHhJbAu3Az5ft9D2yjrSnxFGbIdpGS9sjiDlSc26i32rfODbvvzpbQWW53tcB0n23wtwL4IUQwhkAMLMvAng3gNjFv+/wEH73S2/tsRVSfMFNpdf67kRKXAxRn5dXqZOX9oy4+dQ6GbK1B/StKQKPcbttF1N1st2TmyFbUyzecuC5+Pb63bKd1RbfFDoxN91+GE5zvwF9HV1qjJBNzZua3+1SF9dLUfRdXWvXc9Pa3PeHf/Nbfe+7nSvoCIDzV/0+07U5jrMH2M7i7+vTqJl90MweN7PHy8t8d3Yc58awncU/A+DYVb8fBTC7eaMQwmdDCG8KIbypuC+7jeYcx9lJtvOd/4cA7jCzVwC4AOA3APzmy+3QDBEuNsZ6bPsz67Rdxlp9d0J9h1PfZ8ejCtmerx6SxxxLV8mmvvNPpMtkU3pFQfSnE3PfVe2stAtkU+MZibjfS61h2Y4SO1+d5e/nXyhNkm22OS6PqVDfaVMp1mTuGqLnBsqdHNlGUzzGOIajGtnU9/sRsd31oM7Z6dqBvvZVAqbSLwAttG7WNZTAGseWF38IoWVmHwbwTQARgM+HEJ7a6vEcxxks23nyI4TwdQBf36G+OI4zQNzDz3ESii9+x0ko2/rYf70cy1Tw6enHe2wXWyz4/bixX+5/R2aJbHPtItmUAKMEsuFIO4wox5R9GRb3FoWYlks1yXa+OUG2qXRJtq1EyELEAtDhzDLZnqsdJlucw8iYmI//XWGnJyWQHc6skO2pinbxmKmxONgRotQbCi/xztfxaDqeWSTbMXG9KPJCYD4o5jyrXD+huzmT5/EsdVi4VaLmm3OXZDt/J87v64Z6+/5XQvSNw5/8jpNQfPE7TkLxxe84CcUXv+MkFF/8jpNQthzPvxUOv3o8PPDF+3psP1tlBbPcZAV0w86xAZfXWUHNpNml9MjYKtmaHa2E/7Mjj5Hty/NvJNvxIqvJs9Uxsl0sj5Kt0dIvWt544DzZcilWo6ttnotz6/vIZiKGHABOjLKifLnBb0725/htTEvM26LYFwCKQjUfiviNyFSW334czPA5+87yCdnOeouvmTuGeYzrbd7uojhnB/Pcn+dWtMvu0WF++3FA7K9odPg6eGzuFrlttc7nvLrYe/3P/eF/Qf2lmb5ipv3J7zgJxRe/4yQUX/yOk1B88TtOQhmoe+9aM49HL97ZY5udZ/fP0Ilxo8ywq2lo87b1iEWuZ8+z6BYyWgz7At5CtjOz7HL8whDbVKz6yBDHi6cjnaT0mWV27y032F25XGXhKp3uPxfdC3NTZMtmWVjcP8JuzefP8riP36ZdUpfKLMg2m3zZ1RbZpfq1d58j23NzWnRrVnmOXhjmfkYRz1F5jd2anx9iUXLfCLtEA8BjLx4n2/Awn/NchudXJYatifMdty02n/PrSI/oT37HSSi++B0nofjid5yEsq3v/GZ2FkAJQBtAK4Twpp3olOM4u89OCH6/FkLgYGrBodwa/s3tf91rO8FeXBda7KkG9J/Y8/+usxdYqcWizuuK7E0H6Fj7vx27k2y/Nfl3ZFOx6qebLFLNNDjGHwD+QfFZso2JBKDfWH8N2W7N8ml4S54TYwLAn678EtmOZtlj8a1DZ8l26nZO6lkThTwAIG8snF1qcTGNWzKXybbU5nwJtUO6HZXDoSJi5Ssd9pL71iU+t7cMc76ETEqLtCdu+RHZzlRZUN2XYcFQJTjdH5PrQSWrfXL9aM/v/6vg8fyO41yD7S7+AOCvzexHZvbBneiQ4ziDYbsf+98aQpg1swMAHjGzZ0MI37l6g+5N4YMAsP+w/sjmOM7g2daTP4Qw2/15CcBfYqN45+Ztfl6xZ2xioD5FjuO8DNsp0V0EkAohlLr/fwTAfwoh/FXcPqMjR8Kb3/A7vcZIuCTFOKo1h/nmEdT+wpQpCe8qtS+A6hR/QlHOVc0iGxujbFMFYVJtPe+qWEurwMdsikI82TU+ZietxxjEfTiq8f4imljW2BaRuwCAtviwp46pCs3kV/lCSDX0vFmH7Zk1FhtTDSHapUQ57ZroZCfmwlSJPWPOLyGuwZDRoebWEtWaC70T/IMnPoO19Qu7XqL7IIC/tI2BpwH8j5db+I7j3Fxsp1zXGQCv38G+OI4zQPxVn+MkFF/8jpNQBiq/N4spXHpzb4jn+i0sYuQW9T2p8Wr2kArz7LmnBKnMOnt7icI8AIDOkAgdzgmxp8W6yvhhLtG9OsM54lL7dLWgdp3FHivxaUrt5/3LFXE6427vYo7SC6zOqRSAhYs87sq0bkY4sEE446E9xA3VLvNcxFWgFpWu0Ym4IdW2QgmYcftKsVIUCxJOpmiOCpE2pp3MmhB+R3r3b5zt/3nuT37HSSi++B0nofjid5yE4ovfcRKKL37HSSgDVfs7WaB0W6/8m5pgWbW2T9+TQlmo0dn+3CjrIyw7Z4a1T+pQnt1CVfLEcRE7PTHEbyTUdqmYSjppIVsv1/i1xC2jHG/+7MJBspVX9CuNoTH2Od5/lCXqhTX2I17dx8e0vI51D3U+l9EIz6+icoTnfKioz5mazWadL++cOLfplHjjJJJtNtv6uqw3+bpcK3PeABOJZe85NkM2VREJAF5a4TwXlbne3Agh3b+7vj/5HSeh+OJ3nITii99xEoovfsdJKIPNrmGg2027JHwZY8QwE+KREjhsmMWa9Kxw723oe1/mEO9fmecS1GVj26UVFmtaReF7GnPbjSr8h9YEi1TLq9x2qypOZ0xkd1uIV+df5KSTmWUez/CSOqi+lFTsfifL5zwSeSeVy25zRAuYKt8CxvjaKBf4oJkSz8WacDfOruiT1s7ztjJVhLisfzL/SrJ1hrV4alUhnjY3NSQqWMXhT37HSSi++B0nofjid5yEcs3Fb2afN7NLZnbyKtuEmT1iZqe6P3WVDcdxblr6Efz+BMB/BfCnV9keBPBoCOEhM3uw+/tHt9IB5RkWV6I7iKSIkRBB2nlhE0JPiPFKq5ZE4HVWJJNc4+lr7tPH7BclcqUXVYC3EM1EyfG28GwEgM6LLBimhLekirNvjvD5ya3IZtAWU6mErxZ3B0OXeMPqAX1tRCI9gigWBBOCWHNcTHpRePjFBNq3x3lbE0J0EPkflFKZLmoPyHaWr+vOyiZPwp0s0d3Nw7+5ltK7ATzc/f/DAN7Tf5OO49wMbPU7/8EQwkUA6P7kYnSO49zU7LrgZ2YfNLPHzezx9vr6bjfnOE6fbHXxz5vZNAB0f16K2/Dqij3RsKg04TjODWGrHn5fBfABAA91f36lr706QGqTB1unzV3Irul7Ukc5sCmBbIaFmaE5VkKso9tpiqo7TSFItXMi+WKBt0uvCq+/0RghTghFUV2IQusiieYdQiiq6TG2pkRo65IImRYeeg0haja4and3f+5nJy+87MZEQtJl9sqMe1yp/VtLrDaq/qSFh59d5pDcqKbVtNQCb1s9yGNUhX0y4lrv5PSyjMTYNydTnY+pnKTo51XfnwP4HoA7zWzGzB7AxqJ/p5mdAvDO7u+O4+whrvnkDyG8P+ZPb9/hvjiOM0Dcw89xEoovfsdJKAMN6U21gNzlXoHCgqjKEuOllFLVX0S6s9qU8OY7wtupajIA0Hol5+HrCPEp5PgApiruiHYsJpy4PcYbF6f4Fen+4TLZFtZZlcyl9SCX11iZ/Be//rdkWxS1wMttnotzZe3hfanM+y/McwWj/BArVZ1ZDt9VnpoA0Fxj0W3kKFdPajb5kq9f4rnIiPDddkGHmrfENahE2kxJic68b3pRLwAV6d7mYfeNP/kdJ6H44nechOKL33ESii9+x0koAy7aEVA51usylhIFHEJMcYTsOVY3lNdfanNeMwCNSVG0Q+TbA4Bigb3Fbj0yR7YzS+zWVpllgUtomshOs2AHACOi7bsmue1TK5xvb/0lFtJKhZh8cCIf4hfP/BLv/zwLeZ2D3Mf8KRW7C3REmHGhyuenNsbehe0J4V6owmIBZJb5Qmid477XDynVmI8ZVUQ7MY/KlhACm6LvzQneN7vI/VZhx3FUpnsVw35LkAP+5HecxOKL33ESii9+x0kovvgdJ6H44nechDJQtT+qGcae7W0yXWEpvLCgFeraONtSIqlnO8NqaYi4nUxFu2s2T3FD5/OsHIuCPRjlyteoi363XtSJTUp1tn93nNsOQkW3FNvSS/oUd0QugvVnhYuuKCsdiepH9QntdhvE4yUSLqlK306t8zmLy/WgXKiDGPrwWT6memMUibj4qKavl9yKmPeYPAqE8u+NqbJtgf8w8Wzv74slL9HtOM418MXvOAnFF7/jJJStVuz5uJldMLMnuv/etbvddBxnp9lqxR4A+FQI4RPX01iqCRTmewWO4RlWyOLi+UMkhKYRVbGH922IpJytQlxDbFK6TH1CiGEqyaPYV7m9AkBHiGH5Be2GvJnmsHClnY9xhxVZ1FMi/6cSvoqz7N6bLusqM8uvYgEzU9Hi4GZq+/jc5pe1GJyu8TGjKtsaY3zJN4a5nX77CADV/bx/blXkehCHrO7v79wCQLMorvVc7/ltf38HS3THVOxxHGePs53v/B82sye7Xwu8UKfj7DG2uvg/A+B2APcAuAjgk3EbXl2xp1nXkWyO4wyeLS3+EMJ8CKEdQugA+ByAe19m259X7MnkhFeM4zg3hC15+JnZ9JVCnQDeC+Dky21/heZIwMVf61U97rqTK329MMex6gAwMrxMtuUzIkhaeLpll/k+Vz0YI7qJstbZOREvPswKTnOUj5lZY1EnrvpLblnElguvQeU5l19kW6qpx6iEvOx6f6JZeZpVyZDSmSSV+JoS8ep1IciGNNvaWT1v5UMcyJ4V3m6q8lJ9n0q2KTxCy3ouq/t5//IRISyKUuDpqSrZJsb0J+ShFO+/Wu2d4PC1/kvEX3Pxdyv23Adgv5nNAPiPAO4zs3uwoYufBfChvlt0HOemYKsVe/54F/riOM4AcQ8/x0kovvgdJ6EMNKQXUUBquNcTbGaVk04OF4XCBaDVZhEmf4Rd1Rp1Fn9yx/iY9cv67UOUF4kjT7BXWyQSjWZz7OlWG+kzhhXA+n6R0DHPIk5ocdupjBAq1Viug7YQ55pVUcpbiKwAUBQxzitVno+0qCykSlq3YioQVdbZ+zMS85HPi/OzzqpkZV2VK9cnLYgkqcVxFvIyouTO6BDPz+wFIWIDiMR1kMtfR03uTfiT33ESii9+x0kovvgdJ6H44nechDLYEt2pQKWY20I0K5d09Zd0VlTdEaJOu8LDGp5kwW7NuDQzABlTbEKsCWK7yjKXlVZ58PZNiphaAGsp3j8I0S0lyoMHETI6UtDiqSqTDdFOZoTnTQlxJsa4sS3bU33OZUp4tJVXxfwCSAshT1Ep87WVzYnqOkLAjAuW7Yh5UwJkvsDi3NwCnwdL63DisVH2/Gu0tr6E/cnvOAnFF7/jJBRf/I6TUHzxO05C8cXvOAlloGp/CIZmo48ml1gpBYDmPlZLm3VxvCarr7PnJnm7GHdNUa4d9aru02aUCt+pch+XF0fk/krpTWdZjQ4dkcyxxe7PC7OiXBCAdJHVceWarJR99TakI/oDAHXhaq3e8KjklupNTlYo5hvtCzfkFVb2U2LctZI4t/3n70S6wOenI/ZvnuZznr2N3/rUlvQbjcuz/GYgt6/3bY56axKHP/kdJ6H44nechOKL33ESSj8Ve46Z2bfN7Bkze8rMPtK1T5jZI2Z2qvvT03c7zh6iH8GvBeD3Qwg/NrMRAD8ys0cA/HMAj4YQHjKzBwE8COCjL3egVCmF4e/0utSq5JSNcS1aFH4g4uKFV2m6LlxKhU4UVy2lnRVlnEXZ7+oB3neI85GiLsKza/u1ojQ0x/fjyiu585kFFtIy6pBxRYku86mvp4VAVheuzqoC0ZgeT0ecn+I5nl9VLahyRLt5K9IV7ufQKm9Xm+S2W6LSUScnkpmW9bMy/zxfl2o8qox4vcwi4NQ57SqtkrbmVnvX06xIVBtHPxV7LoYQftz9fwnAMwCOAHg3gIe7mz0M4D19t+o4zg3nur7zm9lxAG8A8BiAg1fSd3d/iudgb9GOVtWLdjjOzULfi9/MhgH8BYDfCyGs9bvf1UU70kNetMNxbhb6WvxmlsHGwv9CCOHLXfO8mU13/z4NQHzbdRznZqWfoh2GjTz9z4QQ/uiqP30VwAcAPNT9+ZVrHSvVBIpzvUJKpsTeUZUGi1kAkC2xCJNfYMWwVeD9lWCXXddq2NJrWBQKIr47Xe7Pm0qJmtkVfd9tD4mKP/M8npGzvG91ivuTW9F9UqXAlYCZXRXefGLfthAGAaAtqh/lL4vko0IgaxWF154Q5wDAxP6NUbapvqdE9aRUXQiDEzoZanuVx5MW33BTLe778AxvV5zrP+lqfXxTP/t38OtL7X8rgN8G8DMze6Jr+3fYWPRfMrMHAJwD8L7+m3Uc50bTT8We7yL+fvL2ne2O4ziDwj38HCeh+OJ3nIQy0JDeqNbCyNNLPTZrsriRe2yJbABgtxwmW/3QMO8/w65d1eMc2lqd1Pe+sRdYWFTlq5fu4ukrH2NRpzgjSlJPaOGqeYi9+dLzrFLVJvmYtcMsrtUOyWZQuMCClvLcq9zCxxx7hvdNV2IETCHu5db4mEoMS7/A+2bWdcUeJRxbSwwoJZKUzojrTbgmhipX4QGAUGG7Ffm1dnthQfRHzOVhfdJCjZXjoVbvuKM1nbBV4U9+x0kovvgdJ6H44nechOKL33ESykAFv+ZoGrP/sNeNTIUppqvTcn9R6AXNYSGm/Sq7qtWnWBBKifLRAKiqEABUZzj0MiUEJeXRtjotSjjHtJ0RuegqKqkg2OtvSIh49QkdaqtCijMlcTKEvlZ6Be+bEnkTAaCd5ZNWXeJ2GiPCy060baI0OQCEtPDqFBHb9f3cn+zKMbJlRPRKuhYTaiuGnhJOeoVLx8nWHBHnTMwFoD0eN4cJN//nN+W+Cn/yO05C8cXvOAnFF7/jJBRf/I6TUHzxO05CGajanx5vYOo953tsZ548QttFMbHhTRFPnZ3nIXREOoDcIquq2dN6+NbiiikT66z0tvPcz+I8b5e7zOp4J6uzGimX1PwsS89WZpfSzpg4ZkzlmfYoV6mJKhwU3xpm12L11iW9XJHtrLyWs5da4AOMnOdzu/haPpGV27V7b36Oz29GxNSrtw/lE6J60Sy33ZgWSQMAFMb5XFQuF8gWrQpX3lu4k5OjOt3d0tn9ZBva3zvvnW/o+VH4k99xEoovfsdJKL74HSehbKdiz8fN7IKZPdH9967d767jODvFdir2AMCnQgif6LexejWL00/1xuRnRKWV7IoW/EaFQKdcOBtjwuV3Hws968e1OBIiUfGnzvdJldSzfIy3aw3phKSKSJTzzq6y0KOQVWK0RyrSFf7D6DkW3aKaKBleYvfnkNWXUqrN7UTCTVYlWC3OCpF1SFdZahXVtrxdYVaUNl9iUbM5JiZOnG8AaJ/k0tkTou91VYlqgd3GS01dvj0vEpKmn+812rqeH0U/OfwuArhSnKNkZlcq9jiOs4fZTsUeAPiwmT1pZp+PK9R5dcWe9vr6tjrrOM7OsZ2KPZ8BcDuAe7DxyeCTar+rK/ZEw5xyy3GcG8OWK/aEEOZDCO0QQgfA5wDcu3vddBxnp9lyxR4zm75SqBPAewGcvOaxOkB6vfd+k1ljEaTFzlEAtOdfRnjeRaIctxLDxn6q730qbjuIxI+RKAXeFH1vjHM7+UUtHkUNEW8uklMqTIhrIdLiqbKnK0IAFd2MymKC50RySgCjZy+wMc2XnWVYFC1OctLViZ/pc2YvXSRbOHKQbXluuzrNJ23tGG9XeFwLt9bmeWsWhPDbZ8XxBuuHAIBORgnMvTZVkSiO7VTseb+Z3YONy+MsgA/136zjODea7VTs+frOd8dxnEHhHn6Ok1B88TtOQhloSG9IsSeWKkmtknoCQJ2jQ1E8zxuv38nqXqrEnk/L99VlO52GqGZTZltqgoWvkWEO7xzLczsLa/q1Zyolwn87PMZ6lcWndFYIgyq7JIAoze0cHCuRrdbiS+TSonA1W2FxDgCiqvCoGxJxxqqfab42LCZRaFRllaydE2KwEI2DcIprTfK5XVuLWy6iTyJsOYg5V5WOVNgxAHQKYt42HzPGC1HhT37HSSi++B0nofjid5yE4ovfcRLKQAW/VAMYfqn3flMTFVSimhZ1OkIIUfn6snM8LCksLnIeOwAYPcv3ROUhWJvkmNF6YNvaPhZq4kJtj72OPdXOP8kVjEKRjzl1YIVsF09NyXZSyzzGc7cI97ASz+XwMc4pWKroSykIj0WM8WSGmhBZ8+w5F6Nfolnm9qNR0Y6Y+PZlcR0I4Sx3TAemtZ8R1ZyEMKmERVUWPbusB1mfYHu7sMkmqztp/MnvOAnFF7/jJBRf/I6TUHzxO05C8cXvOAllsO69EdDc5BnaPMCKbDvGjbJTFHHTY3z/yqwIl8lREave0spo6XahUI+w62yoKPlWmApi3zUdG37+Evswt8d5f+VuvLDCLsNhSCcpbSo1uioqypR5LkuXuTJQJNynAaA9wu1nZ1hdz5S4P+VX8PEKL+l5a4yLN0E18WwT0yFSNSBV4jcf9RXddhhVJYxYxo9K4roUb20yqzHPZNHPzdta/wV7/MnvOEnFF7/jJBRf/I6TUPqp2JM3sx+Y2U+7FXv+oGufMLNHzOxU96dM3e04zs1JP4JfHcDbQgjr3Sy+3zWzbwD4pwAeDSE8ZGYPAngQwEdf7kCZUsD0d3tj21VFl8aoritduMCx8tEiu5qGNItPYZjdbpdfI+LSAeSXhFtpxMdUVWbSVeHKK4TFykEtNqZaLIYpt9D6qKhKdJEFv4lzei6zZbav3C6SVs6L/AIRC1+lW/V4sit8zBx7IcvEpY1R3rcl3LQBIC0qPzWEEKcEyJwo825t4Uob07aqAqSEt9wy759f5e1UJShAX1tRvdc2JxLaxnHNJ3/Y4IpTc6b7LwB4N4CHu/aHAbyn71Ydx7nh9Ju3P+pm7r0E4JEQwmMADl5J3d39eSBm359X7Gk2yzvVb8dxtklfi79bnOMeAEcB3Gtmr+m3gasr9mQy/H7YcZwbw3Wp/SGEFQB/A+B+APNmNg1sFPDAxqcCx3H2CP1U7JkC0AwhrJjZEIB3APjPAL4K4AMAHur+/Mq1jtUcNsz9Sq+glRbfBCKdVxOloyzQ5S+zyFWXJbpVZSAtjmRLLGhlV0W1FFGreGie1TlVVWjlLtk09j0ljEJLaw6zceiS6OO0vr+vCMEw97plss3P8/xmlkW+hLwWFrGfT2Z1XXjKiTj70YMcP19aFXW3AaRnhVAqEngiy/2sT7E6Zw1Rkl14eQJAWZTzzs6wh6ASiNdv4eslqslmkGpzn8pHe/veeLr/eP5+1P5pAA+bWYSNTwpfCiF8zcy+B+BLZvYAgHMA3td3q47j3HD6qdjzJDbKcm+2LwF4+250ynGc3cc9/Bwnofjid5yEMtCQ3qjYQvEtiz22pUVOfmgiHBIA0hkWZlaWue5xSlSJCZMsPEVCJAKA9VdxtRYT4a6qfHVDFK7JLalwVy02Lt/NNlVlRlWjUaWdTVSOAbTXYPk0HyBSJbpFgtWOqK4DAGFBhO+K/U1oabUFnkxR3RsA0BrmayYl2mlnhTee8MBUpeObwnMUAO5+9TmyPW2HydYQSUqz+1jdqy7GiJpr4rrenNQ2LjOswJ/8jpNQfPE7TkLxxe84CcUXv+MklIEKfuPZKt57y097bI/m76Ttmm0trLxx/3my/fQyu9mt1VhkymdYUZqtT+qOCtEkd6BCtkaNp0+V966Pihx+ImQUAKLL7P3WPipCmYX42Vhh8TMaEaWGALRFhZuUyAuovAtrB3g82UntlmaqQk5LhEeLUjyqj4iZNxO5CtMFFm7bl4WYJg7ZOKjKncumcWqeqyKlMixAFsf5GlLjzh/hMHUAKNzG4/nVQ6d7fv+zYW4jDn/yO05C8cXvOAnFF7/jJBRf/I6TUAbr4WcdjGyKV/yXx/4PbddQ7mcA8qJO9n2jz/J2xtsdS3PiuPKdevhnm/vJdrnFoa2r7QLZKh1R5lowFrGIBwApUbP5fI0LeRzPL5HtbI0FzLsLs7Kd1+ZZPD3VOES2cofF08mIQ23vzs7Jdmbb7MH5nfVXke1Envevifrr41H/glYt8P7PVNnzbkLElau24xhLKyGPn6tvHjpDNnWtFVI6pv1Mg5NljaR615O69uPwJ7/jJBRf/I6TUHzxO05C2U7Rjo+b2QUze6L77127313HcXaK7RTtAIBPhRA+sXvdcxxnt+gnjVcAoIp2XDeVdhZPlI712I4OcdLIdVG1BtAK9+UWpwNXinupxa6vbx97WrbzRPlWsrXFhyT19mG2xjHoxTSrt6mYKTxdYfX3RJETI9+RY3X81uwC2ToxH+5mW1xd7cfrPO7vLxwn2+WSKNEd6RwMB0dLZMuk2BX3h8ZtK9fXSlO/TTk8zKVv5sqc8LXW4ku+mGW32YND3O+1Jl9DAHBuhc95JuIxfm/iNrLjjUx5AAAIsUlEQVSdXOA3LCcm+TwCQKvDb8FGs71vjUrtZ+S+iu0U7QCAD5vZk2b2ea/V5zh7i+0U7fgMgNsB3APgIoBPqn2vrthTW4nJSew4zsDZctGOEMJ896bQAfA5APfG7PPzij35cf2xyXGcwdOP2j9lZuPd/18p2vHslWo9Xd4L4OTudNFxnN1gO0U7/szM7sGG+HcWwIeudaBSLY9vP3eixxbNsbinEkQCQF3EkadEvHrqAn/CaO3jfU/dznHYAHD6JOcICKPcTibPx2yuCrFSxHansqKGMwATt+PTkywCPj/Grp7ff+k496eq3VQzQzyewxMcRx7JeHzu5EhBf6WbXeakoCoPwvg4u9iurrGw2FnWgt/5IrtApy/xtpkSX1sqen6R9T402cMbAJBf4jlS3ts/O8DnUfGjV7BLNABZbWh8qtfVutrqz70c2F7Rjt/uuxXHcW463MPPcRKKL37HSSi++B0noQw0nh8BCM3e+01HVJ5Jl7Xgl6qLiiUF3jZ9G8ebF0QCz0pTi2GpKRavRopsy4ljLna4j2mxXb2shZm//6pTZDua51wEuRQf8/IhFsjuHJmX7Xzn4it523HedqHGKldblDufGhK11gHcMf0C2RYbfMzXj3B+AZXH4OQKx+MDwDsOsmfbXJ3FxpcqQhhMsZD2s7lpsgVxbgFgrcmed/k8C6qVCzzukBOekZ2YMttCaC3ker0TVT6IOPzJ7zgJxRe/4yQUX/yOk1B88TtOQrEQU8J5N8gfORaO/c6/6rG1jrOQlnlRxwCo3JiqVLWKlg2qhHSMrhKV+Z7YGhMeeap89TiHh3Yus9efKh8NaAE0UiXHj/C8jY5wIsnlS9pbLFoR1Yby3HYosrCYmeMT0YmTjoWH4NDt7FNXOcvhtx1R6chUVSEAGGOBLYjqSRbjWbmZrPCArC/p0tkm5khVKsqc4f0bk6I/w6JaEACsiSpLm0TwC5/+FOrnz8dc2Zv27Wcjx3F+8fDF7zgJxRe/4yQUX/yOk1AG6uEX0gGNqV6BI5Nmj6TGcV2xJIiSzeOHWTxSYku9yftajCxSnmNPuVtv5zx6q1UWJjNpFnDyk5xfrtzQ3oVrJa4CFIljjgqPw5oYY35Mz2VdhIdihftkKZ7L1jSLmkMjOqS3VmFxMCXOD6ZEP5tC6CxqwW5clL/W51yMR5QMr68K0Tnmegk13r+wn/tTuVWMpyGevzFlyPcdZ0/PleVN16oStmPwJ7/jJBRf/I6TUHzxO05C6Xvxd9N3/8TMvtb9fcLMHjGzU92fnrrbcfYQ1/Pk/wiAq+MmHwTwaAjhDgCPdn93HGeP0Jfab2ZHAfwjAH8I4F93ze8GcF/3/w9jI6X3R1/+QKBklumTovpLTGn05jAr1KUyq7Id4dYJoVpPH2D1FADKeXbDnFkQH2yEcvymW8+R7bbCItlOrum49Gab+94RceQrJe5jW6jWcZV0Ql3MUVYoxW1uW70BqM5oN+IgkpdWLgolXbSdW2PVux2Tn3K1xrH7IepP+baCcM8VKnwQ4waA1Lp4W7DM7somXLLVmwK0tNq/epqvwdxybz+t3pdnL4D+n/yfBvBvAVx9Jg+GEC4CQPcnp5N1HOempZ+8/f8YwKUQwo+20sDVFXva6zrbi+M4g6efj/1vBfBPuiW48wBGzey/A5g3s+kQwsVuAQ/2gsFGxR4AnwWA3PGjgwshdBznZbnmkz+E8LEQwtEQwnEAvwHgWyGE3wLwVQAf6G72AQBf2bVeOo6z42zHvfchAF8yswcAnAPwvmvukQqIhnrFleYIq3utCR3PHK2xONJeYwUof5GHpeL+V5/m8sgAMBQTMr6Zwjwf8/zaCbK9mL+Td475DDTc5D9Ym22dDAs760eUSKXbGbsk3FyLfMyG0PFUXoXRMzEDMp7M9aPcjgmX1rEXWSxcfL0WtFpK3BOm4kH+6jle4PI6F6qTZEuJuH0AKE6L3Ap5dlceynCOgLk1nuDyqs4bEESc/8iJ3tJC0RdicgEIrmvxhxD+BhuqPkIISwDefj37O45z8+Aefo6TUHzxO05C8cXvOAlloAk8zWwBwEvdX/cDYNe3vckv0lgAH8/NzsuN59YQgq49v4mBLv6ehs0eDyG86YY0vsP8Io0F8PHc7OzUePxjv+MkFF/8jpNQbuTi/+wNbHun+UUaC+DjudnZkfHcsO/8juPcWPxjv+MklIEvfjO738yeM7MXzGzPZf8xs8+b2SUzO3mVbU+mNDOzY2b2bTN7xsyeMrOPdO17dTx5M/uBmf20O54/6Nr35HiusFsp9Aa6+M0sAvDfAPw6gLsBvN/M7h5kH3aAPwFw/ybbXk1p1gLw+yGEuwD8MoDf7Z6PvTqeOoC3hRBeD+AeAPeb2S9j747nCruTQi+EMLB/AH4FwDev+v1jAD42yD7s0DiOAzh51e/PAZju/n8awHM3uo9bHNdXALzzF2E8AAoAfgzgLXt5PACOdhf42wB8rWvbkfEM+mP/EQDnr/p9pmvb6+z5lGZmdhzAGwA8hj08nu5H5CewkVzmkRDCnh4PdjGF3qAXvwrG9tcNNxgzGwbwFwB+L4TA9c/2ECGEdgjhHmw8Me81s9fc6D5tle2m0LsWg178MwCOXfX7UQCzA+7DbjDfTWWGl0tpdjNiZhlsLPwvhBC+3DXv2fFcIYSwgo3cE/dj747nSgq9swC+COBtV6fQA7Y3nkEv/h8CuMPMXmFmWWykBfvqgPuwG+zJlGZmZgD+GMAzIYQ/uupPe3U8U2Y23v3/EIB3AHgWe3Q8YbdT6N0AAeNdAJ4HcBrAv7/RgsoW+v/nAC4CaGLjk8wDACaxIcqc6v6cuNH97HMsfw8bX7ueBPBE99+79vB4XgfgJ93xnATwH7r2PTmeTWO7D/9f8NuR8biHn+MkFPfwc5yE4ovfcRKKL37HSSi++B0nofjid5yE4ovfcRKKL37HSSi++B0nofw/2EiR21o7yskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "plt.imshow(downscale_obs(env.render(\"rgb_array\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "\n",
    "def prepare_state(state): #A\n",
    "    return torch.from_numpy(downscale_obs(state, to_gray=True)).float().unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "def prepare_multi_state(state1, state2): #B\n",
    "    state1 = state1.clone()\n",
    "    tmp = torch.from_numpy(downscale_obs(state2, to_gray=True)).float()\n",
    "    state1[0][0] = state1[0][1]\n",
    "    state1[0][1] = state1[0][2]\n",
    "    state1[0][2] = tmp\n",
    "    return state1\n",
    "\n",
    "\n",
    "def prepare_initial_state(state,N=3): #C\n",
    "    state_ = torch.from_numpy(downscale_obs(state, to_gray=True)).float()\n",
    "    tmp = state_.repeat((N,1,1))\n",
    "    return tmp.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(qvalues, eps=None): #A\n",
    "    if eps is not None:\n",
    "        if torch.rand(1) < eps:\n",
    "            return torch.randint(low=0,high=7,size=(1,))\n",
    "        else:\n",
    "            return torch.argmax(qvalues)\n",
    "    else:\n",
    "        return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, N=500, batch_size=100):\n",
    "        self.N = N #A\n",
    "        self.batch_size = batch_size #B\n",
    "        self.memory = [] \n",
    "        self.counter = 0\n",
    "        \n",
    "    def add_memory(self, state1, action, reward, state2):\n",
    "        self.counter +=1 \n",
    "        if self.counter % 500 == 0: #C\n",
    "            self.shuffle_memory()\n",
    "            \n",
    "        if len(self.memory) < self.N: #D\n",
    "            self.memory.append( (state1, action, reward, state2) )\n",
    "        else:\n",
    "            rand_index = np.random.randint(0,self.N-1)\n",
    "            self.memory[rand_index] = (state1, action, reward, state2)\n",
    "    \n",
    "    def shuffle_memory(self): #E\n",
    "        shuffle(self.memory)\n",
    "        \n",
    "    def get_batch(self): #F\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            batch_size = len(self.memory)\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "        if len(self.memory) < 1:\n",
    "            print(\"Error: No data in memory.\")\n",
    "            return None\n",
    "        #G\n",
    "        ind = np.random.choice(np.arange(len(self.memory)),batch_size,replace=False)\n",
    "        batch = [self.memory[i] for i in ind] #batch is a list of tuples\n",
    "        state1_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
    "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
    "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
    "        state2_batch = torch.stack([x[3].squeeze(dim=0) for x in batch],dim=0)\n",
    "        return state1_batch, action_batch, reward_batch, state2_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phi(nn.Module): #A\n",
    "    def __init__(self):\n",
    "        super(Phi, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y)) #size [1, 32, 3, 3] batch, channels, 3 x 3\n",
    "        y = y.flatten(start_dim=1) #size N, 288\n",
    "        return y\n",
    "\n",
    "class Gnet(nn.Module): #B\n",
    "    def __init__(self):\n",
    "        super(Gnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(576,256)\n",
    "        self.linear2 = nn.Linear(256,12)\n",
    "\n",
    "    def forward(self, state1,state2):\n",
    "        x = torch.cat( (state1, state2) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        y = F.softmax(y,dim=1)\n",
    "        return y\n",
    "\n",
    "class Fnet(nn.Module): #C\n",
    "    def __init__(self):\n",
    "        super(Fnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(300,256)\n",
    "        self.linear2 = nn.Linear(256,288)\n",
    "\n",
    "    def forward(self,state,action):\n",
    "        action_ = torch.zeros(action.shape[0],12) #D\n",
    "        indices = torch.stack( (torch.arange(action.shape[0]), action.squeeze()), dim=0)\n",
    "        indices = indices.tolist()\n",
    "        action_[indices] = 1.\n",
    "        x = torch.cat( (state,action_) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnetwork, self).__init__()\n",
    "        #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.linear1 = nn.Linear(288,100)\n",
    "        self.linear2 = nn.Linear(100,12)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        y = y.flatten(start_dim=2)\n",
    "        y = y.view(y.shape[0], -1, 32)\n",
    "        y = y.flatten(start_dim=1)\n",
    "        y = F.elu(self.linear1(y))\n",
    "        y = self.linear2(y) #size N, 12\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':150,\n",
    "    'beta':0.2,\n",
    "    'lambda':0.1,\n",
    "    'eta': 1.0,\n",
    "    'gamma':0.2,\n",
    "    'max_episode_len':100,\n",
    "    'min_progress':15,\n",
    "    'action_repeats':6,\n",
    "    'frames_per_state':3\n",
    "}\n",
    "\n",
    "replay = ExperienceReplay(N=1000, batch_size=params['batch_size'])\n",
    "Qmodel = Qnetwork()\n",
    "encoder = Phi()\n",
    "forward_model = Fnet()\n",
    "inverse_model = Gnet()\n",
    "forward_loss = nn.MSELoss(reduction='none')\n",
    "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "qloss = nn.MSELoss()\n",
    "all_model_params = list(Qmodel.parameters()) + list(encoder.parameters()) #A\n",
    "all_model_params += list(forward_model.parameters()) + list(inverse_model.parameters())\n",
    "opt = optim.Adam(lr=0.001, params=all_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(q_loss, inverse_loss, forward_loss):\n",
    "    loss_ = (1 - params['beta']) * inverse_loss\n",
    "    loss_ += params['beta'] * forward_loss\n",
    "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
    "    loss = loss_ + params['lambda'] * q_loss\n",
    "    return loss\n",
    "\n",
    "def reset_env():\n",
    "    \"\"\"\n",
    "    Reset the environment and return a new initial state\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    return state1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICM(state1, action, state2, forward_scale=1., inverse_scale=1e4):\n",
    "    state1_hat = encoder(state1) #A\n",
    "    state2_hat = encoder(state2)\n",
    "    state2_hat_pred = forward_model(state1_hat.detach(), action.detach()) #B\n",
    "    forward_pred_err = forward_scale * forward_loss(state2_hat_pred, \\\n",
    "                        state2_hat.detach()).sum(dim=1).unsqueeze(dim=1)\n",
    "    pred_action = inverse_model(state1_hat, state2_hat) #C\n",
    "    inverse_pred_err = inverse_scale * inverse_loss(pred_action, \\\n",
    "                                        action.detach().flatten()).unsqueeze(dim=1)\n",
    "    return forward_pred_err, inverse_pred_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_train(use_extrinsic=True):\n",
    "    state1_batch, action_batch, reward_batch, state2_batch = replay.get_batch() \n",
    "    action_batch = action_batch.view(action_batch.shape[0],1) #A\n",
    "    reward_batch = reward_batch.view(reward_batch.shape[0],1)\n",
    "    \n",
    "    forward_pred_err, inverse_pred_err = ICM(state1_batch, action_batch, state2_batch) #B\n",
    "    i_reward = (1. / params['eta']) * forward_pred_err #C\n",
    "    reward = i_reward.detach() #D\n",
    "    if use_explicit: #E\n",
    "        reward += reward_batch \n",
    "    qvals = Qmodel(state2_batch) #F\n",
    "    reward += params['gamma'] * torch.max(qvals)\n",
    "    reward_pred = Qmodel(state1_batch)\n",
    "    reward_target = reward_pred.clone()\n",
    "    indices = torch.stack( (torch.arange(action_batch.shape[0]), \\\n",
    "    action_batch.squeeze()), dim=0)\n",
    "    indices = indices.tolist()\n",
    "    reward_target[indices] = reward.squeeze()\n",
    "    q_loss = 1e5 * qloss(F.normalize(reward_pred), F.normalize(reward_target.detach()))\n",
    "    return forward_pred_err, inverse_pred_err, q_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "env.reset()\n",
    "state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "eps=0.15\n",
    "losses = []\n",
    "episode_length = 0\n",
    "switch_to_eps_greedy = 1000\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "e_reward = 0.\n",
    "last_x_pos = env.env.env._x_position #A\n",
    "ep_lengths = []\n",
    "use_explicit = False\n",
    "for i in range(epochs):\n",
    "    opt.zero_grad()\n",
    "    episode_length += 1\n",
    "    q_val_pred = Qmodel(state1) #B\n",
    "    if i > switch_to_eps_greedy: #C\n",
    "        action = int(policy(q_val_pred,eps))\n",
    "    else:\n",
    "        action = int(policy(q_val_pred))\n",
    "    for j in range(params['action_repeats']): #D\n",
    "        state2, e_reward_, done, info = env.step(action)\n",
    "        last_x_pos = info['x_pos']\n",
    "        if done:\n",
    "            state1 = reset_env()\n",
    "            break\n",
    "        e_reward += e_reward_\n",
    "        state_deque.append(prepare_state(state2))\n",
    "    state2 = torch.stack(list(state_deque),dim=1) #E\n",
    "    replay.add_memory(state1, action, e_reward, state2) #F\n",
    "    e_reward = 0\n",
    "    if episode_length > params['max_episode_len']: #G\n",
    "        if (info['x_pos'] - last_x_pos) < params['min_progress']:\n",
    "            done = True\n",
    "        else:\n",
    "            last_x_pos = info['x_pos']\n",
    "    if done:\n",
    "        ep_lengths.append(info['x_pos'])\n",
    "        state1 = reset_env()\n",
    "        last_x_pos = env.env.env._x_position\n",
    "        episode_length = 0\n",
    "    else:\n",
    "        state1 = state2\n",
    "    if len(replay.memory) < params['batch_size']:\n",
    "        continue\n",
    "    forward_pred_err, inverse_pred_err, q_loss = minibatch_train(use_extrinsic=False) #H\n",
    "    loss = loss_fn(q_loss, forward_pred_err, inverse_pred_err) #I\n",
    "    loss_list = (q_loss.mean(), forward_pred_err.flatten().mean(),\\\n",
    "    inverse_pred_err.flatten().mean())\n",
    "    losses.append(loss_list)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "for step in range(5000):\n",
    "    if done:\n",
    "        env.reset()\n",
    "        state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    q_val_pred = Qmodel(state1)\n",
    "    action = int(policy(q_val_pred,eps))\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    state2 = prepare_multi_state(state1,state2)\n",
    "    state1=state2\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-rl-notebooks-poetry",
   "language": "python",
   "name": "deep-rl-notebooks-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
