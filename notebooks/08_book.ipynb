{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaper 8 - Intrinsic Curiosity Module\n",
    "#### Deep Reinforcement Learning *in Action*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from nes_py.wrappers import JoypadSpace #A\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT #B\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, COMPLEX_MOVEMENT) #C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "for step in range(2500): #D\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize #A\n",
    "import numpy as np\n",
    "\n",
    "def downscale_obs(obs, new_size=(42,42), to_gray=True):\n",
    "    if to_gray:\n",
    "        return resize(obs, new_size, anti_aliasing=True).max(axis=2) #B\n",
    "    else:\n",
    "        return resize(obs, new_size, anti_aliasing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc5e5e08d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXuMXPd1379n3juz7+WSXL5JiZJsyzaVyIpsJa7jR6EoRW0XNWAXDVxAgP1HDTiJgVpui9QpUEAtbCsoWri1ESNK4tpwEqc2DDu2qjiNVduyHpZlWqREUeJzyeVyl/ua9+PXP3bocPb7veRwH0Ou7vkAxOwc3nt/j3vP3JnvPb9zLIQAx3HiR+JGd8BxnBuDO7/jxBR3fseJKe78jhNT3PkdJ6a48ztOTHHnd5yY4s7vODFlTc5vZveb2Ytm9rKZPbRenXIcZ+Ox1Ub4mVkSwEsA3gPgDICnAHwohPBC1D6pfCGkh0aveexWMuI/kqKvwbroLZCoCWN3u0Y2Y2rqlE3sG9XtRFPYGmLDlmjI+KCJWiuiIdUpPmZI8nZB7Bt5ztQ41VyKcau5DCndjJrPVkZsKK4hq/POVhf7RpyzVladC7FhU7SjzreaC0DORyvd+b4+N4tmsdjVlR0xlV1xD4CXQwivAICZfRXAewFEOn96aBT7Hvz9DpsafHVEfyA1hnjjRFV8eRG75yfFdlEnU8yKuriUUybFh0yjr7vjAUBmgW35aXbgVIVtzQyPsXCmLNtpZdlbTXyg1AbTZKvnuZ1avx5QM6smjk2ZeeGU4sOoMqq/rK50AgBY2sNzFAb4pGXO8c65C931GwAWDooLIcV9Ty7ynGdm+aCZRd2OiWbK2zrfn/ofn9M7C9bytX8ngNNXvD/TtjmOswlYi/Orj3r6uDOzj5jZ02b2dKNUXENzjuOsJ2tx/jMAdl/xfheAyZUbhRC+EEK4O4RwdypfWENzjuOsJ2v5zf8UgINmth/AWQAfBPAvrrZDZr6JPd+a7TQm+POnMZCV+6vfpMn5CtnKewbI1sqI339CIAOA6hD3aXEPb5ueF31scB8XbxFti9+EANCc4d+F82/g/RP9rEglU6yJnJ/My3ZChttPjFa5P3O8b2qY5zyTVQoZUJ7sJ1uyKM75r7JYkplkxS5IlRVIlfn8DJzgdrKXhDggSBd5LtMlLZ6OPye0KCG0Wp3nLbnEcx5SEfdk0Xzo6xzP+bkIgVewaucPITTM7GMAvgsgCeBLIYRfrPZ4juP0lrXc+RFC+DaAb69TXxzH6SEe4ec4McWd33Fiypq+9l8v9UIS0/eMdNgGznDkQlRUWhAfVa00C1qpkhBgLrGtvD2n21HxHULPWjgghDgRLZa9wCJeK62Fq9p2no+cENjqJ/nJSeaiCL4Z0u3khRhWL/BcNvp5//Qp3k4F2QBAn4pgE3OZPcbiXlJsVxuICCYSp7K4g/te2s7bpURAXCstxMI5HcZY2s5u1BKCav6cCOiZZ0G0MqrHmL3EtpVRjHVxXqPwO7/jxBR3fseJKe78jhNT3PkdJ6a48ztOTOmp2p+qBgwf7wxnTE+XaLsglpsCQEKEQmKGJdDWnIq75c+5geEh2U7/ji1sbArV/JVT3My+XWQLaTGeiNDii3dxn0KKFeHBkyyF1wa4neKEnssaR0AjRK3JX3nMPfxEIlnW95HcBRHKKyKOlZJtYs5VLgFAP9UYFfGm2QV+QqNyEahQ3lZKt50WS3WzYml2eonnTdlUDgUAqIxdOzRZPSGJwu/8jhNT3PkdJ6a48ztOTHHnd5yY0lPBr9ZvOPv2zjjM3IwOsVUkq0LUeYHFsNQcC3ZqjXRLCXEAirs5dLb/OIuIrRKLlXbsBNkSBU7i17p1N9kAYOC0yjTKJIQYVjjL++YntXi0tJf7VM/ztvkLHJ+7tIPnrR6Rw2/oVbEufpFFrvogX4opIbpFLOdHvV+FK/N26ZII5RVeMPMGFteaEXpboyByOIhEVyElhMFZlTBSt1PZyvPRd75z3E2VtDQCv/M7Tkxx53ecmOLO7zgxZU2/+c3sBIBFAE0AjRDC3evRKcdxNp71EPx+M4RwsavGKsDokU7RQhV7WNqlxaPMAtsX9rFgaC221QZ538KULo3S6ONty7tESNyut5CpleF9VTGNKPFIYSK9QXVY5A2YZ7WnXtBzOX+QbUPH2KZyI2TnhXgaEf124W7eNjfNCVqLO1nlam5hYdAiytkkz/MxayKAc/71ojhIlfueKvN2UVWJ1Nr9VoH72XdKnHQh7tVFDgUAKJxRovUKw3VUofKv/Y4TU9bq/AHA98zsGTP7yHp0yHGc3rDWr/33hRAmzWwrgMfM7GgI4e+v3KD9ofARAMjkR9QxHMe5Aazpzh9CmGy/XgDw11gu3rlym19W7ElnvWKP49wsrPrOb2YFAIkQwmL7738M4D9ebZ9mFpi7dfWfNypJY3WYj1cSiRtV5FNpQg+/ke+uNnRKRIslOdcmqmMqmWPE0lShK6pqwE1R1EiJeykOQgQA5IREW+dgSczfwhOnkmimShEi1Wm2qSW9faIqrp3jQcpy5dDJXZVQGhKs2qljqspLKvEoACRF0tZmmq+XlRV1ASA7x+3kZnQ7xR1sq+ztjOqU5cIjWMvX/m0A/tqW16WnAPyvEMLfrOF4juP0kLWU63oFwJvXsS+O4/QQf9TnODHFnd9xYkpPl/S2MkB5R2fkU6IihJ5GhBg2zGJG8VZWa/rHWOWqVnmolSW9/jHdz0tjk0luu3KJFcjUHLeTFOWjy9u0MJMQK3qb4iypCjk18SS1NiybkZFgJoLnakNiCayaC5H2ENDVcCrbuCGVAzB7ifdtRD0wUuKemKNUkW0Ld/A11HeGJ10KwQCS4hpuim0zIk9haTvvq64BQC9nzpzrHKQJ8TEKv/M7Tkxx53ecmOLO7zgxxZ3fcWKKO7/jxJSeqv35vgruPvRyh60mpOxUxJrtkUyZbGdLvGh7Z56TbQ6n+QlAIiIb5Fydk1vuzrFUe7w0zscUC7T35zmWdr7BbQDAwb4pslWFtH9OLFafERkryxGJAw4NnCFbWsj9p6qjcv+VDKX43EQdsyLGM1nl8WRF3G1fREka1c62NJfNOV7hc6aYuI+voYSKFwZwdGmCbOqcT1b50csuUapInUcASCW4/YEV8eT/88uLcl+F3/kdJ6a48ztOTHHnd5yY4s7vODGlp4Jf0gKG0p0CxRtGztJ2R4osoADA3tws2RpiIfcb+rs75usK52Q7E5k5aV/JwfwFstVFneu78ifIdro2Jo+pxL20sfClxMrb8ywWnhUi0/IxWSA7UuI5Gs+wgDQiYmTPRcQRv65vkmz/T2QPPV3k/WdKLHxdnBqU7SQyPJ6x0SWyvXGMz/nRua1ke9vWV8n2g/O3yLbVMX88u59s+wp8/T5+4XayvXULtw0Az17iKk+7C52CYa3bOuvwO7/jxBZ3fseJKe78jhNTrun8ZvYlM7tgZoevsI2a2WNmdqz96ml5HWeTYSFcPeGfmb0dwBKAPw0h3Nm2/RcAsyGEh83sIQAjIYRPXqux/Nbd4bZ//nsdtqaojiP0LQB6zXhtmKOe+vdydNbSGRaKUkv6s0/NSHOiSrZkmttuzIkcAVnRx1GdWbNc4qSVuT5e4F1a4FwC6T6OfqtP60jCIPqeXGSxqHArz2VJ9LE5KzKKAggZbmf7bha+tuVZnDs6xUJcIqGv18qSmLd+Pmf1mlinX2FbpsBz3jwjMo9CJw/NXmSjShSaFGv3Q8SS/LrQOgunO+fj6P9+BKXp010t6r/mnb+dh3/l2XovgEfbfz8K4H3dNOY4zs3Dan/zbwshnAOA9it/RDuOc1Oz4YKfmX3EzJ42s6cbZZFDyXGcG8JqnX/KzCYAoP3K0S5trqzYk+rzij2Oc7Ow2gi/bwL4MICH26/f6GanZn8L87/eGeFn50QZnghRp1nQSypXsniJhZnsLH/OpRe1LqKCpMo5FvJaopsmklsmihy1t6TK4wBI9LNo12pxP5WYVa2I5buDegnsgR285PT00zvJtqWfv60NjfK+U6Oi1BCAZovnfSjLZY0ODvD9Q0Vv7imILJgAnjjLEXW3jU2T7dAQL2V+YZEjG19d4KXM++8V5YcA3DnAUYw/ubSPbNNlvvn1p1nxOzsvaosDqJX4GqyOdtqa35W7Srp51PcVAD8CcLuZnTGzB7Hs9O8xs2MA3tN+7zjOJuKad/4Qwoci/utd69wXx3F6iEf4OU5Mced3nJhyzQi/9SS7Z3eY+OTHO2zDL/Dnz9Ke7o+pquFkOHWbpLhTj33wONsaovy1ikRsiUA3FbEVkQ5OVtKpDXE/W+IHW0ipstIRoqawqdSJOVE6uzzBezf69YCspsp5iypA6geo6HpuRo9Hlc8ubxWj3MeRlanDLMSpuWhFrJatbBcbywlmU7LExmafnsvsDHdgZYTr5Gf+CNVT6xTh5zjOaxN3fseJKe78jhNT3PkdJ6b0NIcfApBYIQCVtylBSO/eSrOKUt3KYksro5ZTCg0kIpJwaa/YVgij9RFuW5ZIFkJRQgg9AKBqX7T2s7F5SS+hpe2ioiKFOVHhPhV3iV3FEuVkUY+nlVXzxvtnp3mSqqM8v+WtWstS7agl2/UFseR6gPdVYm6I8hYl5Im2mznRjtAKM7MRyqI4Z5kVkatRy+EVfud3nJjizu84McWd33Fiiju/48QUd37HiSm9VfsTgUIXVfJDU8o8tBKuVFVFbYil0qgQWxVqml7iPiWEQq0qbzfHOPa0mdNlyBN53jaXY9tSldseHOm+DPnCAnc0iBDmIBKSBvHUpRkxmaGPx5m6yHkHquIJQFI8fYgipHh/FVadudjdJa+U+ajMmkE8NVLTrpKmNvpV7LfuU6LK/0Hh7V0F9raP1/2mjuO8lnDnd5yY4s7vODFltRV7Pm1mZ83sufa/Bza2m47jrDfdqB9/AuC/AfjTFfZHQgifuZ7GEukWCts7E0L25zgR5UJJJPUEUL7IiTmtyQqHlNIKHPfYKukwSrXGujrGYo1aK68EzOSMSKwZEVrcusSnpNrgcQ+dFfkFmhzymy7pdlSB8IaedsZ43ipbtNLUzPGEDIgK1NVR3q4yJkJ2i1Hr+blPK0PJAaDRJ3IeqDwGouJO8VZRXgeACSEP89yfHQc48enOfq6I9NRhXQo8DHP7rRXXURCh11GstmKP4zibnLX85v+YmT3f/lnghTodZ5OxWuf/PIBbABwCcA7AZ6M27KjYsxCxXM9xnJ6zKucPIUyFEJohhBaALwK45yrb/kPFnkFd5dRxnN6zqgg/M5u4XKgTwPsBHL7a9pfJpep4/dbzHbatWS7NnFIKDID5XRyVNlXmSjGHhrkqS17UQp5X4XgAtooMoD+YOUi2fYUZuf9Kig0W4rZldZbRqSrXYT46x3VQR+7lcEcVzTeY5uo4AFAT2SiPTG8jm4lj7hjkvk8t6oo9iQQLUKm72DYmqvjs6efqPNMVXeloconnbdfAHNlySRZ+d/bxdhdr3M5ElsU5AHi5OM5Godnt7uPxqPP9zkMvyHb29LH0Nl3rnPe/zOnzrbim87cr9rwDwBYzOwPgPwB4h5kdwnKO0hMAPtp1i47j3BSstmLPH29AXxzH6SEe4ec4McWd33FiSk8r9uTHd4c73v97Hba6WkYa8WMkIQKsaqKacaOfx5ReEFViRODdsp337xOVa6rDvK9KyCj1y4hpb4n8kqoajUrUmL3EB80UIyIJVXCjCJ5rZNmoogZTVd1OPa8iEUXTYvd6n1hGrbVgNMW5VP1UEZittLg2xPxklvQYu+27aludn6a4BgCgIY65kqNffwSlaa/Y4zjOVXDnd5yY4s7vODHFnd9xYkpvc/gZECKKkVxJXQdxSUFKiYDKpoS0ZEQwVEaIg6kyCzO5WbaVt/Dnad+0yN0mhDBAC025OW6nJoRSNca5HfrzXYluKkVdQlWAEWs8m0IYBHROQyWwqRSANQ5+i7x+lABaFheMEoPVMZXom17Uc6ny/WXmuhP8qiIvX9TSajVHK/seJWIr/M7vODHFnd9xYoo7v+PEFHd+x4kp7vyOE1N6qva3UlxfXYapRmQMFHkspRqdEBV/lLIfHd7LtuowH7M22F3IcHGCP2NVyG4UFZEkrTImwm6LvF16UR9T5PpES9hMPDlRqvXSbq32J0WVpcp4d4k5U+KciXytAICseCKizpmCqt4ASIkKTeoJCQCkSt2FB+vQYrbJakEAkhX1hGfFtl6xx3Gca+HO7zgxxZ3fcWJKNxV7dpvZ983siJn9wsw+3raPmtljZnas/erpux1nE9GN4NcA8IkQwrNmNgDgGTN7DMC/AvB4COFhM3sIwEMAPnnVIyVYzFDlsBuFiP2FDqJCWhWZeVZC6oNaWJFhrkKgUxV7lFijwkeVoAQAISXKPSuVS3R9aY8oQx4lUhWFCCnEPRVqnRQhqZXtuqGkaKcxqkqW84XQEnMUtda9qUqjZ8UkqXLaQiBWlX2ixDQl5KlF/uo8tkQf0/P6nlwfEMe8piGabir2nAshPNv+exHAEQA7AbwXwKPtzR4F8L7um3Uc50ZzXb/5zWwfgLsAPAlg2+X03e1Xzi+NzqIdzaJ4FuU4zg2ha+c3s34AfwXgd0MIOum84MqiHclC1Pd5x3F6TVfOb2ZpLDv+l0MIX2+bp8xsov3/EwAubEwXHcfZCLop2mFYztN/JITwuSv+65sAPgzg4fbrN651rGAc0aSEtEY+Irul+KgyJboVWHwKCVbdWjldzlgJM1J0E6b6ELedqHLH67rAjey7/IjOiu1qvKGJtgGgLirptIZEuKRKTjkkLpt+HbLYGhIHqPC5SI5zOF/YyvsmI0qbh+P8rXLgJJ8gFQnYECKtXDsfJfiJ6WileN6z8yKvg0jKWeLCSe1OqXYitu2Cbna9D8DvAPi5mT3Xtv1bLDv918zsQQCnAHxg9d1wHKfXdFOx5wlEP0B41/p2x3GcXuERfo4TU9z5HSem9HRJb7IK9J/o/AVREdEBuYjoNxXhlF7kbfufZ0GpLp4y1oZ0Nki5TFjoWUlRpSZR4ykVFb+RmdfCVXmc91cVYZpZ3q46IgQysQwU0GNMnufwOSUolfbwzrag10e3sixypWf4oPURcR9K8njyoyXZTkMIdHO/wiGLiXluOzvDc5S7KM5txDLs0nbev29KLDEe5DGqZdTJqm4nLfxiZXShWiIfhd/5HSemuPM7Tkxx53ecmOLO7zgxpaeCn7W48k3/SbFdRIBfU+T2CyLiS1WJaeZYLMksRIhuW8W2c7xdK6ny+nXXH5X/DwDqoqKMEufUMlJlk8taAVS3iUjEEh9ALTHOj/MCrWxaK01zp7mOuYzgVCtoRXRiuSgUMgCJ/SLhX0mIr3NqjLyrqkAUVTpeCbopkbtQjVstJ1YVmpb3v/Z6XRWZGIXf+R0nprjzO05Mced3nJjizu84McWd33FiSk/V/uZQC0sPLHXYGnUOsd06qhMFNWocQmri0cClWc46GRrX8TlXV+vv2dYc43jPxDz3sbGVlfDWBR0O2+xnuTak2ZZc4FOnlPlERImb5CLPu0r2mZ4R454bJNuCeKIBAGGYx55aEir8lAhrFsp1vRCRn0AlY83xgKpb2aZyQqh8C83+iGyoLZE3YFqEmIsnORB5DAoD4skFgAMj/Ljr9MJQp+Fvuo/v9Tu/48QUd37HiSnu/I4TU9ZSsefTZnbWzJ5r/3tg47vrOM56sZaKPQDwSAjhM902FoKhWu4UuvoKvHh58lxE5S+VQVHFAotElimxjju9oMUwKnsMXUo596IONV1JKcXiT06sIQeAmhAmkyLhpQ7j7K6yDwA0hPiUFKWm1fQmaqI8eITOZCohgMrpuYUHlLso5kJUCwKAhJhPFdKtqic189y2EuyqOv2DnLfaiDhBQywQhyW+sBbL2i2PVHnbZjNx1fdXo5scfucAXC7OsWhmlyv2OI6ziVlLxR4A+JiZPW9mX4oq1NlRsWfBK/Y4zs3CWir2fB7ALQAOYfmbwWfVfh0Vewa9Yo/j3CysumJPCGEqhNAMIbQAfBHAPRvXTcdx1ptVV+wxs4nLhToBvB/A4Wsda29hBv/1bX/WYTtdH6PtflbcLfc/2McVwXakL5Htp6W9ZKsK4WlLeolsAHBn32myvTFzkWx/WzpAtpPVLWRLi9C5fESWxqVmTtpXkhXZJOcbebK9tf+Y3H+mwVGQP168lWz3DrxMtuEkJ9GcbnDUHwA0xf3lQp237U9yVJuat6j5qQhF9sGRn5BtvsWq3RdnfoNseVGv/E15vi4A4JniPrINiQX9by3oc7GSqLnMiXN+otZ5vT2SX+yqDWBtFXs+ZGaHsKzdngDw0a5bdRznhrOWij3fXv/uOI7TKzzCz3Fiiju/48SUni7pbSCB2Wan0HQwe562+4388a6PeVqII3uyM2TLXEcpkzRYaDpWHyJbU2TM3JaeJ1slsBg1mtRioxLtJkT20DGx/1yS91VjAYBbMiye7htjUfNAitt5osyC7NHyhGznjr5zZLs7/yr3U5yfs3UOHbmvjwVIADjb5PPzwwrHog0nWKx8fX6St0tyTEpJldcBcN8AC3kLQpicabLIerLGAnE9ou72gSyfs93pzmW+GbUuOwK/8ztOTHHnd5yY4s7vODHFnd9xYkpPBb9yK4PD5V0dtgNCePpheb/cf3eahTwVIXhbhkXE7yy8iWxKSAN0ZNlAgiO2LjY40VtCrLU9kJkm22JLR6rd2XeGbElxzJpYm6rm54WqXoDZEmLlxToLUukEz8UHh54imxI1o1gQY9+XZrFRRbT9uMxRlQAwKoTJMzW+Np6rc/SnivRUgmrOdI1uJVb+ao6jASvinKnzsNDSCRF/vHQL2d62QmyMWMEt8Tu/48QUd37HiSnu/I4TU9z5HSemuPM7TkzpqdpfSFRxd6EztPNolcNCF5ta7TxvXOv9oFD2nyzxunS1PvtQ7pRup8GhooMJXm9+e45DVxVFERYaFd67MvwZAN6df4Vs40k+5s94iBgQ/QaWz8VKmmLx5qgIc322yuG9UyL8GQDu6jtBtmO17WSrB74U55ocrnxRldIBMC+23ZLite13ChW+DlbhdyY5TPsnFf0USvVTnfOdKc49obYbFE+WAOD+oZ+TbWW48vWEsfud33Fiiju/48QUd37HiSndVOzJmdlPzOxn7Yo9f9i2j5rZY2Z2rP0aUWnDcZybkW4EvyqAd4YQltpZfJ8ws+8A+GcAHg8hPGxmDwF4CMAnr3agJFokUKjEi7szHKYKANuFCHNerOMeEgkm1VpoJTYCOmxXJaJU4Z5KLBxPcclxJexFbfuiENOqgeei1OLcBlGi5lxECOlK1Br0HHjcKukpACyKdlRIqwqRLbUyZHtzXo8nbyxgqnOhUKLoTItFPBXyCwCTIu/AnhSX0z5R57X7SniNQgmLK8OqG4EF8CiueecPy1wedbr9LwB4L4BH2/ZHAbyv61Ydx7nhdJu3P9nO3HsBwGMhhCcBbLucurv9ujVi319W7Jmb7T7LiOM4G0tXzt8uznEIwC4A95jZnd02cGXFnuHRiEqHjuP0nOtS+0MIcwD+DsD9AKbMbAJYLuCB5W8FjuNsErqp2DMOoB5CmDOzPgDvBvCfAXwTwIcBPNx+/ca1jlVsZfFkqXNNsqo8c6mha/rdV3hJHnMlav27Sqg4LiLAAOBUldeBT9Y5urAqxMrbRNSfil6rCRsAvFjZQTYVlfYDsa5dCVdREX4qZ4FaR65ENyV0DqdZZAWAitj2h6Iy0PNLu8h2aIDFvajIyL9fuoNsuzIsuikBUtlyIiL0e3NvkG3vyLL4erbBIqCa3z0iB4PKdwDo/ARHip2i9VxDC6+KbtT+CQCPmlkSy98UvhZC+JaZ/QjA18zsQQCnAHyg61Ydx7nhdFOx53ksl+VeaZ8B8K6N6JTjOBuPR/g5Tkxx53ecmNLTJb1LzSyevLSvw3bHwBRtN1PXgt+36ofItj3DEXFVIaaVmixcFZu6AsubCiyaqKjD7Ulu+5nKPt4uxYlC782dlG3fkuaIulKLxaevLLL4oxJ43plRNVaBkw1eqjsplpIer3D4xu1ZFjXvyuilpP+nzOM5ssBLencXeLnr0wv7yPadC/opc3+aI+XSgyxqJtIsBv+suIds0zXu92xVX5e35vlB1/9duJ1sqjLQ8RrPrxJZAeBslUXElxc6owZVKfoo/M7vODHFnd9xYoo7v+PEFHd+x4kpPRX8tmfm8Yld3+2wTTd5GaqKxgOAnWkWhU7Uxsn2RhERF1VeWTEu8tap/HbHhFijcszVRaWWqCW9x+ocLTbX7C5VgqpeNNvUS0YPpDn6TVXIUZGAKmLxpbquFaNKRv/m+Itk25bicasy4k8UWUgDgFuzLBy/XN1GtouipPsHRrgC0XiSxU8VVRnFgUGu0qQE2UkRCaiqMQE6InVnttMnjqd1/j+F3/kdJ6a48ztOTHHnd5yY4s7vODGlp4LfpUYBf3Hpng7bvhyXZt6XYRsA/Kh4kGz9SV6y+uczbyPbr/TriDqFyrV2ssq2/SIvYEsIg88tcgTZWwZfJRsAHKty9NuzYn/Fnj4W8fZE5EO8IPIUnqrxGNXy6CNi2bHKLwcAs02Oinu1zCLtj4SYNpblZcLzdS0GL/azfVZEimYSHIn486V3kO2giNp7YoZLZANAvcUC3T8aP0Y2NUffv8RLkadFVCQAZFPc98SKotxLjWflvgq/8ztOTHHnd5yY4s7vODFlLUU7Pm1mZ83sufa/Bza+u47jrBdrKdoBAI+EED6zcd1zHGej6CaNVwCginZcN/MLBXz7sbd02FopPlQrqw+fm2JVtd4vthVL2L9XeQsbIwiiT2rE9V28zl6tF2/N8vrsxyOyn4cch8NaicedqPMgk2W2qT4CQKjxlz7LctuH9neXEPLE3Jul/dJZrpqTqHDbySr3PXuRbRF5T/F8/jayNfJ80pqjrJj3v8Dn5wfb+Tw2B3TdifQsd+qr81zGvHibOBdNcbE2dA4GdQ3mxjvDeSt1TiobxVqKdgDAx8zseTOVBf6ZAAAITElEQVT7ktfqc5zNxVqKdnwewC0ADgE4B+Czat8rK/Y0i7xgxnGcG8Oqi3aEEKbaHwotAF8EcE/EPr+s2JMs6DRIjuP0nm7U/nEzG27/fblox9HL1XravB/A4Y3pouM4G8Fainb8mZkdwrIMcQLAR695oOFL+Pfv+4sOm1rvHRUqqirpvCnPgtSwKNGtjvliRZfoHk3xz5NjZV67f7CPQ0CPVzh0dSTF/VFhwACHawLA3iyHO/+8yBVuTpdZdmkF3c7ePIcC78xyotEdIoeCPD8cGQwAGL6dx/58icWwqSqvs58RCTPvGTkh25msckWlvX08b6MiV8PsPdxOTpQMV9cAACSsO/1bhbKrCkSqghCwXOJ+JQMrwtv/IM95EaJYS9GO3+m6Fcdxbjo8ws9xYoo7v+PEFHd+x4kpPV7Pn8dfTt3dYVOCVJRIlUtygsluObzAa9CrDT38sRyLQksNTgD6izkWDFNi/ftBkcwxqrLKdIXXcv8ULJDNVVkU2lFgsSeR0GLU8SUWJlXJ8WcXOJfAglhTX6zrKjMlEXG2LS9ErjrP70KF2/kx9st2BtOc12FS5AgoNbifw1lOenm+yAJk1HW5o5/nXW370gILhm8be4Vs8w0t+L1aZMF7ZT+nqyfkvgq/8ztOTHHnd5yY4s7vODHFnd9xYkpPBb+EBeRTncsaTy5wVNqvbdXJNvMJXhL5zCwLUkp8arT4c257gSugAEBNJGRUxxzKsFA0nmMxqx647VNLehHkQo2Fr7E+jpJLJzkycrbKkXcr5/uXx8yyqKn6mU5wOzNlbmeiwOXKAWAgzXOp2m6ItgcGuNqQEjoBYFHMW73JbW/pE9GbsxyeWMiwuFyOWC5babBdRXCOioSkhxdZiFbXKgDUhEh8+3BnlOlLSV0qXeF3fseJKe78jhNT3PkdJ6a48ztOTOmp4GfgCLiRHItm5aYWVpTgMV/lKLBhccxZIVKlhJgFAPM1FpXUsk1VUUYer87H25aPEMgyLCzOVHjJaV+KBSklKJWEGLXcJ543NcaMmKOMEBtVRBwAbBdC4HCa+zlV4QpCCiV0AlpoVQKoiiTcPSgi9IRgl09r8VS1LSNXxTGnixzROZLT11Ur6LGvFr/zO05Mced3nJjizu84MaVr52+n7/6pmX2r/X7UzB4zs2PtV0/d7TibiOu5838cwJEr3j8E4PEQwkEAj7ffO46zSehK7TezXQB+G8B/AvD7bfN7Abyj/fejWE7p/cmrHSeAVVC1Rv+VRZ0NUoU95kTN8jePnOWdxfeS2ZpOJa5CYpNCCT9XZoVbKeY1EWbaFOGsgM4loPaviFwEqk68Oh6gQ1onBjjcuSCU7LdvfZlsT83ule1UxJMbtS5d5UHIiScaCbEdoJ/cbO3j8ezPz5Dt5/McYrtNjPvwrE74eqzBuREGs5xfYFeeE6QqZX9JPJGIYmVeiBCRGFbR7Z3/jwD8G6Ajfei2EMI5AGi/6tSmjuPclHSTt/+fALgQQnhmNQ1cWbGneok/DR3HuTF087X/PgD/tF2COwdg0Mz+HMCUmU2EEM61C3hwEnssV+wB8AUAGH3d+KoKfDqOs/5c884fQvhUCGFXCGEfgA8C+NsQwr8E8E0AH25v9mEA39iwXjqOs+6sJbz3YQBfM7MHAZwC8IFr7dAMCUr++NI5lgoyWb0mOSPEvWyabd87dYdom4WQWk0Pf7DAP09KVQ67NSHuHRzjZJ0HhrhSy2xNVyU6Ps9CXL8IKx3IcB9Pzo+SbSKigosS9zIJnsupMofdTha57LbKQwDo8O1ZEa68q5/FMNX2y8e3y3ZyZ1hYVCW6n8izYGgtvjYSNbalSlpMq/cLEVJs+osuFbZUUbdT2yLCe5OdY1wqdy8WXpfzhxD+DsuqPkIIMwDedT37O45z8+ARfo4TU9z5HSemuPM7TkyxEHr39M3MpgFczs65BQArYZuT19JYAB/Pzc7VxrM3hMAhh4KeOn9Hw2ZPhxDuvvaWNz+vpbEAPp6bnfUaj3/td5yY4s7vODHlRjr/F25g2+vNa2ksgI/nZmddxnPDfvM7jnNj8a/9jhNTeu78Zna/mb1oZi+b2abL/mNmXzKzC2Z2+ArbpkxpZma7zez7ZnbEzH5hZh9v2zfreHJm9hMz+1l7PH/Ytm/K8Vxmo1Lo9dT5zSwJ4L8D+C0ArwfwITN7fS/7sA78CYD7V9g2a0qzBoBPhBBeB+BeAP+6fT4263iqAN4ZQngzgEMA7jeze7F5x3OZjUmhF0Lo2T8AbwXw3SvefwrAp3rZh3Uaxz4Ah694/yKAifbfEwBevNF9XOW4vgHgPa+F8QDIA3gWwK9t5vEA2NV28HcC+Fbbti7j6fXX/p0ATl/x/kzbttnZ9CnNzGwfgLsAPIlNPJ72V+TnsJxc5rEQwqYeDzYwhV6vnV8tVPbHDTcYM+sH8FcAfjeEoOuIbRJCCM0QwiEs3zHvMbM7b3SfVstaU+hdi147/xkAu694vwvAZI/7sBFMtVOZ4WopzW5GzCyNZcf/cgjh623zph3PZUIIc1jOPXE/Nu94LqfQOwHgqwDeeWUKPWBt4+m18z8F4KCZ7TezDJbTgn2zx33YCDZlSjMzMwB/DOBICOFzV/zXZh3PuJkNt//uA/BuAEexSccTNjqF3g0QMB4A8BKA4wD+3Y0WVFbR/68AOAegjuVvMg8CGMOyKHOs/Tp6o/vZ5Vh+Hcs/u54H8Fz73wObeDxvAvDT9ngOA/iDtn1TjmfF2N6BfxD81mU8HuHnODHFI/wcJ6a48ztOTHHnd5yY4s7vODHFnd9xYoo7v+PEFHd+x4kp7vyOE1P+P58Rm5QhdEqkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "plt.imshow(downscale_obs(env.render(\"rgb_array\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from collections import deque\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Pytorch using device:', device)\n",
    "\n",
    "def prepare_state(state): #A\n",
    "    return torch.from_numpy(downscale_obs(state, to_gray=True)).float().unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "def prepare_multi_state(state1, state2): #B\n",
    "    state1 = state1.clone()\n",
    "    tmp = torch.from_numpy(downscale_obs(state2, to_gray=True)).float()\n",
    "    state1[0][0] = state1[0][1]\n",
    "    state1[0][1] = state1[0][2]\n",
    "    state1[0][2] = tmp\n",
    "    return state1\n",
    "\n",
    "\n",
    "def prepare_initial_state(state,N=3): #C\n",
    "    state_ = torch.from_numpy(downscale_obs(state, to_gray=True)).float()\n",
    "    tmp = state_.repeat((N,1,1))\n",
    "    return tmp.unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(qvalues, eps=None): #A\n",
    "    if eps is not None:\n",
    "        if torch.rand(1) < eps:\n",
    "            return torch.randint(low=0,high=7,size=(1,))\n",
    "        else:\n",
    "            return torch.argmax(qvalues)\n",
    "    else:\n",
    "        return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ExperienceReplay:\n",
    "    def __init__(self, N=500, batch_size=100):\n",
    "        self.N = N #A\n",
    "        self.batch_size = batch_size #B\n",
    "        self.memory = [] \n",
    "        self.counter = 0\n",
    "        \n",
    "    def add_memory(self, state1, action, reward, state2):\n",
    "        self.counter +=1 \n",
    "        if self.counter % 500 == 0: #C\n",
    "            self.shuffle_memory()\n",
    "            \n",
    "        if len(self.memory) < self.N: #D\n",
    "            self.memory.append( (state1, action, reward, state2) )\n",
    "        else:\n",
    "            rand_index = np.random.randint(0,self.N-1)\n",
    "            self.memory[rand_index] = (state1, action, reward, state2)\n",
    "    \n",
    "    def shuffle_memory(self): #E\n",
    "        shuffle(self.memory)\n",
    "        \n",
    "    def get_batch(self): #F\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            batch_size = len(self.memory)\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "        if len(self.memory) < 1:\n",
    "            print(\"Error: No data in memory.\")\n",
    "            return None\n",
    "        #G\n",
    "        ind = np.random.choice(np.arange(len(self.memory)),batch_size,replace=False)\n",
    "        batch = [self.memory[i] for i in ind] #batch is a list of tuples\n",
    "        state1_batch = torch.stack([x[0].squeeze(dim=0) for x in batch],dim=0)\n",
    "        action_batch = torch.Tensor([x[1] for x in batch]).long()\n",
    "        reward_batch = torch.Tensor([x[2] for x in batch])\n",
    "        state2_batch = torch.stack([x[3].squeeze(dim=0) for x in batch],dim=0)\n",
    "        return state1_batch, action_batch, reward_batch, state2_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phi(nn.Module): #A\n",
    "    def __init__(self):\n",
    "        super(Phi, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y)) #size [1, 32, 3, 3] batch, channels, 3 x 3\n",
    "        y = y.flatten(start_dim=1) #size N, 288\n",
    "        return y\n",
    "\n",
    "class Gnet(nn.Module): #B\n",
    "    def __init__(self):\n",
    "        super(Gnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(576,256)\n",
    "        self.linear2 = nn.Linear(256,12)\n",
    "\n",
    "    def forward(self, state1,state2):\n",
    "        x = torch.cat( (state1, state2) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        y = F.softmax(y,dim=1)\n",
    "        return y\n",
    "\n",
    "class Fnet(nn.Module): #C\n",
    "    def __init__(self):\n",
    "        super(Fnet, self).__init__()\n",
    "        self.linear1 = nn.Linear(300,256)\n",
    "        self.linear2 = nn.Linear(256,288)\n",
    "\n",
    "    def forward(self,state,action):\n",
    "        action_ = torch.zeros(action.shape[0],12) #D\n",
    "        indices = torch.stack( (torch.arange(action.shape[0]), action.squeeze()), dim=0)\n",
    "        indices = indices.tolist()\n",
    "        action_[indices] = 1.\n",
    "        x = torch.cat( (state,action_) ,dim=1)\n",
    "        y = F.relu(self.linear1(x))\n",
    "        y = self.linear2(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnetwork, self).__init__()\n",
    "        #in_channels, out_channels, kernel_size, stride=1, padding=0\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=2, padding=1)\n",
    "        self.linear1 = nn.Linear(288,100)\n",
    "        self.linear2 = nn.Linear(100,12)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        y = F.elu(self.conv1(x))\n",
    "        y = F.elu(self.conv2(y))\n",
    "        y = F.elu(self.conv3(y))\n",
    "        y = F.elu(self.conv4(y))\n",
    "        y = y.flatten(start_dim=2)\n",
    "        y = y.view(y.shape[0], -1, 32)\n",
    "        y = y.flatten(start_dim=1)\n",
    "        y = F.elu(self.linear1(y))\n",
    "        y = self.linear2(y) #size N, 12\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size':150,\n",
    "    'beta':0.2,\n",
    "    'lambda':0.1,\n",
    "    'eta': 1.0,\n",
    "    'gamma':0.2,\n",
    "    'max_episode_len':100,\n",
    "    'min_progress':15,\n",
    "    'action_repeats':6,\n",
    "    'frames_per_state':3\n",
    "}\n",
    "\n",
    "replay = ExperienceReplay(N=1000, batch_size=params['batch_size'])\n",
    "Qmodel = Qnetwork()\n",
    "encoder = Phi()\n",
    "forward_model = Fnet()\n",
    "inverse_model = Gnet()\n",
    "forward_loss = nn.MSELoss(reduction='none')\n",
    "inverse_loss = nn.CrossEntropyLoss(reduction='none')\n",
    "qloss = nn.MSELoss()\n",
    "all_model_params = list(Qmodel.parameters()) + list(encoder.parameters()) #A\n",
    "all_model_params += list(forward_model.parameters()) + list(inverse_model.parameters())\n",
    "opt = optim.Adam(lr=0.001, params=all_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(q_loss, inverse_loss, forward_loss):\n",
    "    loss_ = (1 - params['beta']) * inverse_loss\n",
    "    loss_ += params['beta'] * forward_loss\n",
    "    loss_ = loss_.sum() / loss_.flatten().shape[0]\n",
    "    loss = loss_ + params['lambda'] * q_loss\n",
    "    return loss\n",
    "\n",
    "def reset_env():\n",
    "    \"\"\"\n",
    "    Reset the environment and return a new initial state\n",
    "    \"\"\"\n",
    "    env.reset()\n",
    "    state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    return state1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICM(state1, action, state2, forward_scale=1., inverse_scale=1e4):\n",
    "    state1_hat = encoder(state1) #A\n",
    "    state2_hat = encoder(state2)\n",
    "    state2_hat_pred = forward_model(state1_hat.detach(), action.detach()) #B\n",
    "    forward_pred_err = forward_scale * forward_loss(state2_hat_pred, \\\n",
    "                        state2_hat.detach()).sum(dim=1).unsqueeze(dim=1)\n",
    "    pred_action = inverse_model(state1_hat, state2_hat) #C\n",
    "    inverse_pred_err = inverse_scale * inverse_loss(pred_action, \\\n",
    "                                        action.detach().flatten()).unsqueeze(dim=1)\n",
    "    return forward_pred_err, inverse_pred_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch_train(use_extrinsic=True):\n",
    "    state1_batch, action_batch, reward_batch, state2_batch = replay.get_batch() \n",
    "    action_batch = action_batch.view(action_batch.shape[0],1) #A\n",
    "    reward_batch = reward_batch.view(reward_batch.shape[0],1)\n",
    "    \n",
    "    forward_pred_err, inverse_pred_err = ICM(state1_batch, action_batch, state2_batch) #B\n",
    "    i_reward = (1. / params['eta']) * forward_pred_err #C\n",
    "    reward = i_reward.detach() #D\n",
    "    if use_explicit: #E\n",
    "        reward += reward_batch \n",
    "    qvals = Qmodel(state2_batch) #F\n",
    "    reward += params['gamma'] * torch.max(qvals)\n",
    "    reward_pred = Qmodel(state1_batch)\n",
    "    reward_target = reward_pred.clone()\n",
    "    indices = torch.stack( (torch.arange(action_batch.shape[0]), \\\n",
    "    action_batch.squeeze()), dim=0)\n",
    "    indices = indices.tolist()\n",
    "    reward_target[indices] = reward.squeeze()\n",
    "    q_loss = 1e5 * qloss(F.normalize(reward_pred), F.normalize(reward_target.detach()))\n",
    "    return forward_pred_err, inverse_pred_err, q_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 8.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e74b34db76487cb73f674ba2653499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-8acb8fb27d16>:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.multinomial(F.softmax(F.normalize(qvalues)), num_samples=1) #B\n"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, COMPLEX_MOVEMENT) #C\n",
    "\n",
    "epochs = 5000\n",
    "env.reset()\n",
    "state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "eps=0.15\n",
    "losses = []\n",
    "episode_length = 0\n",
    "switch_to_eps_greedy = 1000\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "e_reward = 0.\n",
    "last_x_pos = env.env.env._x_position #A\n",
    "ep_lengths = []\n",
    "use_explicit = False\n",
    "for i in trange(epochs):\n",
    "    opt.zero_grad()\n",
    "    episode_length += 1\n",
    "    q_val_pred = Qmodel(state1) #B\n",
    "    if i > switch_to_eps_greedy: #C\n",
    "        action = int(policy(q_val_pred,eps))\n",
    "    else:\n",
    "        action = int(policy(q_val_pred))\n",
    "    for j in range(params['action_repeats']): #D\n",
    "        state2, e_reward_, done, info = env.step(action)\n",
    "        last_x_pos = info['x_pos']\n",
    "        if done:\n",
    "            state1 = reset_env()\n",
    "            break\n",
    "        e_reward += e_reward_\n",
    "        state_deque.append(prepare_state(state2))\n",
    "    state2 = torch.stack(list(state_deque),dim=1) #E\n",
    "    replay.add_memory(state1, action, e_reward, state2) #F\n",
    "    e_reward = 0\n",
    "    if episode_length > params['max_episode_len']: #G\n",
    "        if (info['x_pos'] - last_x_pos) < params['min_progress']:\n",
    "            done = True\n",
    "        else:\n",
    "            last_x_pos = info['x_pos']\n",
    "    if done:\n",
    "        ep_lengths.append(info['x_pos'])\n",
    "        state1 = reset_env()\n",
    "        last_x_pos = env.env.env._x_position\n",
    "        episode_length = 0\n",
    "    else:\n",
    "        state1 = state2\n",
    "    if len(replay.memory) < params['batch_size']:\n",
    "        continue\n",
    "    forward_pred_err, inverse_pred_err, q_loss = minibatch_train(use_extrinsic=False) #H\n",
    "    loss = loss_fn(q_loss, forward_pred_err, inverse_pred_err) #I\n",
    "    loss_list = (q_loss.mean(), forward_pred_err.flatten().mean(),\\\n",
    "    inverse_pred_err.flatten().mean())\n",
    "    losses.append(loss_list)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "state_deque = deque(maxlen=params['frames_per_state'])\n",
    "for step in range(5000):\n",
    "    if done:\n",
    "        env.reset()\n",
    "        state1 = prepare_initial_state(env.render('rgb_array'))\n",
    "    q_val_pred = Qmodel(state1)\n",
    "    action = int(policy(q_val_pred,eps))\n",
    "    state2, reward, done, info = env.step(action)\n",
    "    state2 = prepare_multi_state(state1,state2)\n",
    "    state1=state2\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you're done, run env.close()\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-rl-notebooks-poetry",
   "language": "python",
   "name": "deep-rl-notebooks-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
